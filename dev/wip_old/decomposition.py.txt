# hint, if not None, should contain repeat_count column collections that will be
# placed in the beginning of a corresponding permutation component
# while the all others will be placed at the end of the component
# e.g. [[col_a], [col_b], [col_c]] mean that for the component '0'
# col_a should be at the beginning and col_b and col_c at the end
def generate_permutation(df, dec, repeat_count, hint=None, random_state=None):
    random_state = check_random_state(random_state)
    cols = df.columns[df.columns != dec]
    beginning = []
    end = []
    if hint is not None:
        assert len(hint) == repeat_count
        hint_all_cols = pd.Series(list(itertools.chain(*hint)))
        cols = cols[~cols.isin(hint_all_cols)]
        for i in range(repeat_count):
            beginning.extend(itertools.product([i], hint[i]))
            end.extend(itertools.product([i], hint_all_cols[~hint_all_cols.isin(hint[i])]))
        beginning = sklearn.utils.shuffle(beginning, random_state = random_state)
        end = sklearn.utils.shuffle(end, random_state = random_state)
    middle = sklearn.utils.shuffle(list(itertools.product(xrange(repeat_count), cols)), random_state = random_state)
    return list(itertools.chain(beginning, middle, end))

def create_function_covered_many_times(times):
    def covered_many_times(df, dec, decomposition):
        counts = pd.Series(list(itertools.chain(*[v['objects'] for k, v in decomposition.iteritems()]))).value_counts()
        return len(counts) == len(df) and (counts >= times).all()
    return covered_many_times

def draw_objects_using_stats(df, dec, cols, already_drawn_objects, draw_stats, draw_relatively, draw_randomized, random_state=None):
    random_state = check_random_state(random_state)
    def fun(x):
        drawn = x.index.isin(already_drawn_objects)
        if drawn.any():
            # if the  given group already contains any objects get these objects
            result = x[drawn]
            assert len(result[dec].value_counts()) == 1
            assert len(x[x[dec] == result[dec].iloc[0]]) == len(result)
        else:
            # otherwise, create ranking of decisions to choose, select detetrministically or randomly the decision,
            # and get all objects with the choosen decision
            local_dec_values = x[dec].value_counts().index
            rank_dec = []
            for dec_val in local_dec_values:
                rank_dec_item = [draw_stats['apriori'][dec_val] - draw_stats['current'][dec_val], dec_val]
                if draw_relatively:
                    rank_dec_item[0] /= float(draw_stats['apriori'][dec_val])
                rank_dec.append(rank_dec_item)
            if draw_randomized:
                dec_to_randomize_draw_values = local_dec_values
                dec_to_randomize_draw_weights = [v[0] for v in rank_dec]
                drawn_dec = pd.Series(dec_to_randomize_draw_values).sample(weights=dec_to_randomize_draw_weights).iloc[0]
            else:
                drawn_dec = sorted(rank_dec, reverse=True)[0][1]
            result = x[x[dec] == drawn_dec]
            for k, v in result[dec].value_counts().iteritems():
                draw_stats['current'][k] += v

        return result

    if not cols:
        df3 = fun(df)
    else:
        # there is a problem with apply fun with side effects, i.e. fun is applied to the first group two times
        # therefore it is done manually by iteration with for loop on groups
#         df3 = df.groupby(cols, group_keys=False, sort=False).apply(fun)
        df2_list = []
        for k, v in df.groupby(cols, group_keys=False, sort=False):
            df2_list.append(fun(v))
        df3 = pd.concat(df2_list)

    return df3.sort_index().index.tolist()

def shuffled_decision_values(df, dec, n, random_state=None):
    random_state = check_random_state(random_state)
    return list(itertools.islice(itertools.cycle(df[dec].value_counts().sort_values().index), n))

def decompose_using_stats(df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, random_state=None):
    random_state = check_random_state(random_state)
    cols = df.columns[df.columns != dec].tolist()
    dec_value_counts = df[dec].value_counts() * split_count
    draw_stats = {'apriori': dec_value_counts, 'current': dict(zip(dec_value_counts.index, itertools.repeat(0)))}
    result = dict(zip(
                itertools.count(0),
                [{'columns': [],
                  'objects': df[df[dec] == dec_value].index.tolist()
                 }
                 for dec_value in shuffled_decision_values(df, dec, split_count)
                ]))
    permutation = generate_permutation(df, dec, split_count, partition(cols, split_count, random_state = random_state), random_state = random_state)
    for split_id, col in permutation:
        if end_decomposition_f(df, dec, result):
            break
        result[split_id]['columns'].append(col)
        result[split_id]['objects'] = draw_objects_using_stats(
            df,
            dec,
            result[split_id]['columns'],
            result[split_id]['objects'],
            draw_stats,
            draw_relatively,
            draw_randomized,
            random_state
            )
    # if one of the superbireducts is a superreduct then leave only this one
    for k, v in result.iteritems():
        if len(v['objects']) == len(df):
            result = {k: v}
            break
    # reduce columns
    for k, v in result.iteritems():
        v['columns'] = orig_cols_order(
            cols,
            reduction_functional_dependency_preserve(df, dec, reversed(v['columns']), v['objects'])
            )
        v['df'] = df.loc[v['objects'], v['columns'] + [dec]]
    return result.values()

def repeated_decompose(df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, repetitions, random_state=None):
    random_state = check_random_state(random_state)
    best_decomposition = None
    best_decomposition_max_cols = None
    best_reduct_cols = None
    for i in range(repetitions):
        decomposition = decompose_using_stats(df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, random_state)
        max_cols = max(map(len, map(operator.itemgetter('columns'), decomposition)))
        if best_decomposition_max_cols is None or max_cols < best_decomposition_max_cols:
            best_decomposition = decomposition
            best_decomposition_max_cols = max_cols
        if len(decomposition) == 1 and (best_reduct_cols is None or max_cols < len(best_reduct_cols)):
            best_reduct_cols = decomposition[0]['columns']
    return {'best_reduct_cols': best_reduct_cols, 'decomposition': best_decomposition}

def get_decomposition_tree(df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, repetitions, random_state=None):
    random_state = check_random_state(random_state)
    result = repeated_decompose(df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, repetitions, random_state = random_state)
    if len(result['decomposition']) > 1:
        new_result = []
        for element in result['decomposition']:
            element_df = df.loc[element['objects'], element['columns'] + [dec]]
            new_result.append(get_decomposition_tree(element_df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, repetitions, random_state = random_state))
        result['decomposition'] = new_result
    return dict(starting_df=df, **result)

def get_decomposition_tree_stats(decomposition_tree):
    if len(decomposition_tree['decomposition']) == 1:
        no_of_cols = len(decomposition_tree['decomposition'][0]['columns'])
        result = {'depth': 1, 'leafs': 1, 'nodes': 1, 'leaf_max_col': no_of_cols, 'quality': [no_of_cols]}
    else:
        result = {
                    'depth': 1 + max(map(operator.itemgetter('depth'), map(get_decomposition_tree_stats, decomposition_tree['decomposition']))),
                    'leafs': sum(map(operator.itemgetter('leafs'), map(get_decomposition_tree_stats, decomposition_tree['decomposition']))),
                    'nodes': 1 + sum(map(operator.itemgetter('nodes'), map(get_decomposition_tree_stats, decomposition_tree['decomposition']))),
                    'leaf_max_col': max(map(operator.itemgetter('leaf_max_col'), map(get_decomposition_tree_stats, decomposition_tree['decomposition']))),
                    'quality': sorted(itertools.chain(*map(operator.itemgetter('quality'), map(get_decomposition_tree_stats, decomposition_tree['decomposition']))), reverse=True),
                 }
    result['best_reduct_cols_len'] = len(decomposition_tree['best_reduct_cols']) if decomposition_tree['best_reduct_cols'] is not None else None
    return result

def get_decomposition_forest(df, dec, split_count, end_decomposition_f, draw_relatively, draw_randomized, trees=1, repetitions=5, random_state=None):
    random_state = check_random_state(random_state)
    result = []
    for i in range(trees):
        print 'tree', i, '/', trees
        tree = get_decomposition_tree(
                df[orig_cols_order(df.columns, get_random_reduct(df, dec, random_state = random_state)) + [dec]],
                dec,
                split_count,
                end_decomposition_f,
                draw_relatively,
                draw_randomized,
                repetitions,
                random_state = random_state
                )
        tree['stats'] = get_decomposition_tree_stats(tree)
        result.append(tree)
    return result

def process_trees(df, dec, times_repeated, n_folds, split_count, draw_relatively, draw_randomly, trees_to_create, repetitions, random_state=None):
    assert isinstance(random_state, int) or random_state is None
    result = {}
    result['info'] = {
                        'df': df,
                        'dec': dec,
                        'times_repeated': times_repeated,
                        'n_folds': n_folds,
                        'split_count': split_count,
                        'draw_relatively': draw_relatively,
                        'draw_randomly': draw_randomly,
                        'trees_to_create': trees_to_create,
                        'repetitions': repetitions,
                        'random_state': random_state,
                        }
    result['tree_models'] = []
    random_state = check_random_state(random_state)
    all_kfolds = [KFold(len(df), n_folds, shuffle=True, random_state=random_state) for _ in range(times_repeated)]
    for iteration, kfolds in itertools.izip(itertools.count(), all_kfolds):
        tree_kfolds_result = []
        for k, (tr_idxs, te_idxs) in itertools.izip(itertools.count(), kfolds):
            print 'iteration', iteration, k
            df_tr = df.iloc[tr_idxs]
            df_te = df.iloc[te_idxs]
            forest = get_decomposition_forest(
                        df_tr,
                        dec,
                        split_count,
                        create_function_covered_many_times(math.ceil(split_count / 2.0)),
                        draw_relatively,
                        draw_randomly,
                        trees_to_create,
                        repetitions,
                        random_state = random_state)
            tree_kfolds_result.append((df_tr, df_te, forest))
        result['tree_models'].append(tree_kfolds_result)
    return result


# my_df = df_zoo
# my_dec = dec_zoo
# split_count = 3
# trees = 10
# seed = 999
# x = get_decomposition_forest(my_df, my_dec, split_count, create_function_covered_many_times(math.ceil(split_count / 2.0)),
#                              draw_relatively = False, draw_randomized = False, use_local_draw_stats = False,
#                              trees = trees, repetitions = 5, random_state = seed)
# xx = x[np.argmin([get_decomposition_tree_stats(t)['quality'] for t in x])]

# y = get_decomposition_forest(my_df, my_dec, split_count, create_function_covered_many_times(math.ceil(split_count / 2.0)),
#                              draw_relatively = False, draw_randomized = False, use_local_draw_stats = True,
#                              trees = trees, repetitions = 5, random_state = seed)
# yy = y[np.argmin([get_decomposition_tree_stats(t)['quality'] for t in y])]



# draw_decomposition_tree(xx)
# draw_decomposition_tree(yy)

# for i in range(10):
#     print i
#     print '---------- False-False'
#     x = get_decomposition_forest(my_df, my_dec, split_count, create_function_covered_many_times(math.ceil(split_count / 2.0)), False, False, trees = trees, repetitions = 5, random_state = i)
#     for y in x:
#         print get_decomposition_tree_stats(y)
#     print '---------- True-False'
#     x = get_decomposition_forest(my_df, my_dec, split_count, create_function_covered_many_times(math.ceil(split_count / 2.0)), True, False, trees = trees, repetitions = 5, random_state = i)
#     for y in x:
#         print get_decomposition_tree_stats(y)
#     print '---------- False-True'
#     x = get_decomposition_forest(my_df, my_dec, split_count, create_function_covered_many_times(math.ceil(split_count / 2.0)), False, True, trees = trees, repetitions = 5, random_state = i)
#     for y in x:
#         print get_decomposition_tree_stats(y)
#     print '---------- True-True'
#     x = get_decomposition_forest(my_df, my_dec, split_count, create_function_covered_many_times(math.ceil(split_count / 2.0)), True, True, trees = trees, repetitions = 5, random_state = i)
#     for y in x:
#         print get_decomposition_tree_stats(y)


# trees_3_t_f = process_trees(df_zoo, dec_zoo, 10, 5, 3, True, False, 100, 5, 2016)
# print '---------- 3_t_t'
# trees_3_t_t = process_trees(df_zoo, dec_zoo, 10, 5, 3, True, True, 100, 5, 2016)
# print '---------- bireducts'
# bireducts = process_bireducts(df_zoo, dec_zoo, 10, 5, 0.06, 500, 2016)
