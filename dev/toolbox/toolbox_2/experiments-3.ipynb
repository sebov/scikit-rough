{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import attr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import auc, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from skrough.base import Bireduct\n",
    "from skrough.bireducts.dynamically_adapted_approximate_bireduct import (\n",
    "    DynamicallyAdaptedApproximateBireduct,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(config.DATA_DIR)\n",
    "TMP_DIR = pathlib.Path(config.TMP_DIR)\n",
    "SEP = \",\"\n",
    "DISCRETIZED_SEP = \";\"\n",
    "N_JOBS = 7\n",
    "\n",
    "# DISCRETIZED_FILEPATH_IN = DATA_DIR / 'toolbox_tabular_data_annonymized_discretized_uniform.csv'\n",
    "DISCRETIZED_FILEPATH_IN = (\n",
    "    DATA_DIR / \"toolbox_tabular_data_annonymized_discretized_quantile.csv\"\n",
    ")\n",
    "# DISCRETIZED_FILEPATH_IN = DATA_DIR / 'toolbox_tabular_data_annonymized_discretized_kmeans.csv'\n",
    "FILEPATH_IN = DATA_DIR / \"toolbox_tabular_data_annonymized.csv\"\n",
    "\n",
    "EMBEDDINGS_FILEPATH_IN = DATA_DIR / \"process_embeddings_d50.csv\"\n",
    "\n",
    "FEATURE_GROUPS_FILEPATH_IN = DATA_DIR / \"feature_groups.csv\"\n",
    "\n",
    "XGBOOST_EXPERIMENT_DIR = \"paper_xgboost_3_\"\n",
    "XGBOOST_FILENAME_OUT_TEMPLATE = (\n",
    "    f\"{XGBOOST_EXPERIMENT_DIR}/\"\n",
    "    \"xgboost_native\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_k_{k}\"\n",
    "    \"_num_boost_round_{num_boost_round}\"\n",
    "    \"_learning_rate_{learning_rate}\"\n",
    "    \"_max_depth_{max_depth}\"\n",
    "    \"_base_score_{base_score}\"\n",
    "    \".csv\"\n",
    ")\n",
    "\n",
    "XGBOOST_FILENAME_OUT_TEMPLATE_SAME_CATEGORY = (\n",
    "    f\"{XGBOOST_EXPERIMENT_DIR}/\"\n",
    "    \"xgboost_native\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_same_category\"\n",
    "    \"_num_boost_round_{num_boost_round}\"\n",
    "    \"_learning_rate_{learning_rate}\"\n",
    "    \"_max_depth_{max_depth}\"\n",
    "    \"_base_score_{base_score}\"\n",
    "    \".csv\"\n",
    ")\n",
    "XGBOOST_WO_FEATURES_FILENAME_OUT_TEMPLATE = (\n",
    "    f\"{XGBOOST_EXPERIMENT_DIR}/\"\n",
    "    \"xgboost_native\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_k_{k}\"\n",
    "    \"_num_boost_round_{num_boost_round}\"\n",
    "    \"_learning_rate_{learning_rate}\"\n",
    "    \"_max_depth_{max_depth}\"\n",
    "    \"_base_score_{base_score}\"\n",
    "    \"_without_feature_group_{group_name}\"\n",
    "    \".csv\"\n",
    ")\n",
    "\n",
    "TREE_EXPERIMENT_DIR = \"paper_tree_3_\"\n",
    "TREE_FILENAME_OUT_TEMPLATE = (\n",
    "    f\"{TREE_EXPERIMENT_DIR}/\"\n",
    "    \"decision_tree\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_k_{k}\"\n",
    "    \"_min_impurity_decrease_{min_impurity_decrease}\"\n",
    "    \"_max_depth_{max_depth}\"\n",
    "    \".csv\"\n",
    ")\n",
    "TREE_FILENAME_OUT_TEMPLATE_SAME_CATEGORY = (\n",
    "    f\"{TREE_EXPERIMENT_DIR}/\"\n",
    "    \"decision_tree\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_same_category\"\n",
    "    \"_min_impurity_decrease_{min_impurity_decrease}\"\n",
    "    \"_max_depth_{max_depth}\"\n",
    "    \".csv\"\n",
    ")\n",
    "\n",
    "TREE_WO_FEATURES_FILENAME_OUT_TEMPLATE = (\n",
    "    f\"{TREE_EXPERIMENT_DIR}/\"\n",
    "    \"decision_tree\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_k_{k}\"\n",
    "    \"_min_impurity_decrease_{min_impurity_decrease}\"\n",
    "    \"_max_depth_{max_depth}\"\n",
    "    \"_without_feature_group_{group_name}\"\n",
    "    \".csv\"\n",
    ")\n",
    "\n",
    "\n",
    "BIREDUCTS_EXPERIMENT_DIR = \"paper_bireducts_3_\"\n",
    "BIREDUCTS_FILENAME_OUT_TEMPLATE = (\n",
    "    f\"{BIREDUCTS_EXPERIMENT_DIR}/\"\n",
    "    \"bireducts\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_k_{k}\"\n",
    "    \"_n_bireducts_{n_bireducts}\"\n",
    "    \"_candidate_n_attrs_{candidate_n_attrs}\"\n",
    "    \"_allowed_randomness_{allowed_randomness}\"\n",
    "    \"_max_n_attrs_{max_n_attrs}\"\n",
    "    \"_iteration_{iteration}\"\n",
    "    \".csv\"\n",
    ")\n",
    "BIREDUCTS_FILENAME_OUT_TEMPLATE_SAME_CATEGORY = (\n",
    "    f\"{BIREDUCTS_EXPERIMENT_DIR}/\"\n",
    "    \"bireducts\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_same_category\"\n",
    "    \"_n_bireducts_{n_bireducts}\"\n",
    "    \"_candidate_n_attrs_{candidate_n_attrs}\"\n",
    "    \"_allowed_randomness_{allowed_randomness}\"\n",
    "    \"_max_n_attrs_{max_n_attrs}\"\n",
    "    \"_iteration_{iteration}\"\n",
    "    \".csv\"\n",
    ")\n",
    "BIREDUCTS_WO_FEATURES_FILENAME_OUT_TEMPLATE = (\n",
    "    f\"{BIREDUCTS_EXPERIMENT_DIR}/\"\n",
    "    \"bireducts\"\n",
    "    \"_dataset_{dataset}\"\n",
    "    \"_leave_one_process_out_k_{k}\"\n",
    "    \"_n_bireducts_{n_bireducts}\"\n",
    "    \"_candidate_n_attrs_{candidate_n_attrs}\"\n",
    "    \"_allowed_randomness_{allowed_randomness}\"\n",
    "    \"_max_n_attrs_{max_n_attrs}\"\n",
    "    \"_iteration_{iteration}\"\n",
    "    \"_without_feature_group_{group_name}\"\n",
    "    \".csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=TMP_DIR / \"b.log\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(EMBEDDINGS_FILEPATH_IN)\n",
    "process_category = embeddings[[\"process_ids\", \"process_category\"]]\n",
    "embeddings.drop([\"process_category\"], axis=1, inplace=True)\n",
    "embeddings.set_index(\"process_ids\", inplace=True)\n",
    "emb_nbrs = NearestNeighbors().fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = pd.read_csv(FEATURE_GROUPS_FILEPATH_IN)\n",
    "\n",
    "group_names = [\n",
    "    \"employment history\",\n",
    "    \"skills\",\n",
    "    \"education\",\n",
    "    \"place of residence\",\n",
    "    \"current status\",\n",
    "    \"job offer\",\n",
    "    \"person-offer relation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(FILEPATH_IN, sep=SEP)\n",
    "# process_ids = df.pop('process_ids')\n",
    "# df_dec = df.pop('target').astype('category').cat.codes\n",
    "# df_dec = 1 - df_dec\n",
    "\n",
    "# discretized_df = pd.read_csv(DISCRETIZED_FILEPATH_IN, sep=DISCRETIZED_SEP)\n",
    "# discretized_process_ids = discretized_df.pop('process_ids')\n",
    "# discretized_df = discretized_df.astype('category')\n",
    "# discretized_df = discretized_df.apply(lambda x: x.cat.codes)\n",
    "# discretized_df_dec = discretized_df.pop('target')\n",
    "# discretized_df_dec = 1 - discretized_df_dec\n",
    "\n",
    "# assert (process_ids == discretized_process_ids).all()\n",
    "# assert (df_dec == discretized_df_dec).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_train(train, test, process_ids, embeddings, emb_nbrs, k):\n",
    "    # search for k+1 neighbors because the one we search for is obviously the best match (thus +1)\n",
    "    test_process_id = process_ids.loc[test.index[0]]\n",
    "    nbrs = emb_nbrs.kneighbors(\n",
    "        [embeddings.loc[test_process_id]], n_neighbors=k + 1, return_distance=False\n",
    "    )[0]\n",
    "    return train[process_ids.loc[train.index].isin(embeddings.index[nbrs])]\n",
    "\n",
    "\n",
    "def fit_predict_xgboost_native(train, test, df_dec, **fit_predict_params):\n",
    "    params = dict(\n",
    "        fit_predict_params, objective=\"binary:logistic\", eval_metric=\"logloss\"\n",
    "    )\n",
    "    num_boost_round = params.pop(\"num_boost_round\")\n",
    "    dtrain = xgb.DMatrix(train.values, label=df_dec.loc[train.index])\n",
    "    dtest = xgb.DMatrix(test.values)\n",
    "    cl = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n",
    "    scores = cl.predict(dtest)\n",
    "    return (\n",
    "        pd.Series(scores, index=test.index),\n",
    "        pd.Series(1, index=test.index),\n",
    "        pd.Series(1, index=test.index),\n",
    "    )\n",
    "\n",
    "\n",
    "def fit_predict_decision_tree(train, test, df_dec, **fit_predict_params):\n",
    "    cl = tree.DecisionTreeClassifier(**fit_predict_params)\n",
    "    cl = cl.fit(train.values, df_dec.loc[train.index])\n",
    "    scores = cl.predict_proba(test)[:, 1]\n",
    "    return (\n",
    "        pd.Series(scores, index=test.index),\n",
    "        pd.Series(1, index=test.index),\n",
    "        pd.Series(1, index=test.index),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_bireducts(\n",
    "    train,\n",
    "    df_dec,\n",
    "    n_bireducts,\n",
    "    n_of_probes,\n",
    "    allowed_randomness,\n",
    "    candidate_n_attrs,\n",
    "    max_n_attrs,\n",
    "):\n",
    "    ghr = DynamicallyAdaptedApproximateBireduct(\n",
    "        n_of_probes=n_of_probes,\n",
    "        allowed_randomness=allowed_randomness,\n",
    "        candidate_n_attrs=candidate_n_attrs,\n",
    "        max_n_attrs=max_n_attrs,\n",
    "    )\n",
    "    ghr.fit(train, df_dec.loc[train.index], check_data_consistency=False)\n",
    "    bireducts = Parallel(n_jobs=N_JOBS)(\n",
    "        delayed(ghr.get_bireduct)() for i in range(n_bireducts)\n",
    "    )\n",
    "    return bireducts\n",
    "\n",
    "\n",
    "def predict(train, test, bireduct, df_dec):\n",
    "    objs = bireduct.objects\n",
    "    cols = bireduct.attributes\n",
    "    bireduct_train = train.iloc[objs, cols]\n",
    "    bireduct_train = bireduct_train.drop_duplicates()\n",
    "    nn = NearestNeighbors().fit(bireduct_train)\n",
    "    dist, neighbors = nn.kneighbors(\n",
    "        test.iloc[:, cols], n_neighbors=1, return_distance=True\n",
    "    )\n",
    "    result = [\n",
    "        df_dec.loc[bireduct_train.index[n[0]]] if d[0] == 0 else np.nan\n",
    "        for d, n in zip(dist, neighbors)\n",
    "    ]\n",
    "    return result\n",
    "\n",
    "\n",
    "def fit_predict_bireducts(train, test, df_dec, **fit_predict_params):\n",
    "    params = dict(fit_predict_params, n_of_probes=100)\n",
    "    bireducts = get_bireducts(train, df_dec, **params)\n",
    "    scores = np.zeros(len(test))\n",
    "    counts = np.zeros(len(test))\n",
    "    counts2 = np.zeros(len(test))\n",
    "    for bireduct in bireducts:\n",
    "        for i, dec in enumerate(predict(train, test, bireduct, df_dec)):\n",
    "            if not np.isnan(dec):\n",
    "                scores[i] += int(dec)\n",
    "                counts[i] += 1\n",
    "                counts2[i] += len(bireduct.objects) / len(train)\n",
    "    return (\n",
    "        pd.Series(scores, index=test.index),\n",
    "        pd.Series(counts, index=test.index),\n",
    "        pd.Series(counts2, index=test.index),\n",
    "    )\n",
    "\n",
    "\n",
    "def do_leave_one_process_out_k(\n",
    "    fit_predict_fun, df, df_dec, process_ids, k, **fit_predict_params\n",
    "):\n",
    "    logging.info({\"filename\": FILEPATH_IN})\n",
    "    logging.info({\"k\": k})\n",
    "    logging.info(fit_predict_params)\n",
    "    scores = pd.Series(dtype=\"float\")\n",
    "    counts = pd.Series(dtype=\"float\")\n",
    "    counts2 = pd.Series(dtype=\"float\")\n",
    "    i = 0\n",
    "    for train_index, test_index in tqdm.tqdm(\n",
    "        LeaveOneGroupOut().split(df, df_dec, groups=process_ids)\n",
    "    ):\n",
    "        i += 1\n",
    "        logging.info(str(i))\n",
    "        train = df.iloc[train_index]\n",
    "        test = df.iloc[test_index]\n",
    "        if k is not None:\n",
    "            train = refine_train(train, test, process_ids, embeddings, emb_nbrs, k)\n",
    "        s, c, c2 = fit_predict_fun(train, test, df_dec, **fit_predict_params)\n",
    "        scores = scores.append(s)\n",
    "        counts = counts.append(c)\n",
    "        counts2 = counts2.append(c2)\n",
    "    return scores.sort_index(), counts.sort_index(), counts2.sort_index()\n",
    "\n",
    "\n",
    "def do_leave_one_process_out_same_category(\n",
    "    fit_predict_fun, df, df_dec, process_ids, process_category, **fit_predict_params\n",
    "):\n",
    "    logging.info(\"same category\")\n",
    "    logging.info(fit_predict_params)\n",
    "    scores = pd.Series(dtype=\"float\")\n",
    "    counts = pd.Series(dtype=\"float\")\n",
    "    counts2 = pd.Series(dtype=\"float\")\n",
    "    i = 0\n",
    "    for leave_one_out_process_id in tqdm.tqdm(process_category[\"process_ids\"].unique()):\n",
    "        i += 1\n",
    "        logging.info(str(i))\n",
    "        test = df[process_ids == leave_one_out_process_id]\n",
    "        test_category = process_category[\n",
    "            process_category[\"process_ids\"] == leave_one_out_process_id\n",
    "        ][\"process_category\"].iloc[0]\n",
    "        test_category_process_ids = process_category[\n",
    "            process_category[\"process_category\"] == test_category\n",
    "        ][\"process_ids\"]\n",
    "        train = df[\n",
    "            process_ids.isin(test_category_process_ids)\n",
    "            & (process_ids != leave_one_out_process_id)\n",
    "        ]\n",
    "        s, c, c2 = fit_predict_fun(train, test, df_dec, **fit_predict_params)\n",
    "        scores = scores.append(s)\n",
    "        counts = counts.append(c)\n",
    "        counts2 = counts2.append(c2)\n",
    "    return scores.sort_index(), counts.sort_index(), counts2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = FILEPATH_IN\n",
    "df = pd.read_csv(data_filepath, sep=SEP)\n",
    "process_ids = df.pop(\"process_ids\")\n",
    "df_dec = df.pop(\"target\").astype(\"category\").cat.codes\n",
    "df_dec = 1 - df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [08:33, 28.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-456fc3b04e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rate_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_depth_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     x = do_leave_one_process_out_k(fit_predict_xgboost_native,\n\u001b[0m\u001b[1;32m     19\u001b[0m                                                    \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                    \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4da8cfcbf370>\u001b[0m in \u001b[0;36mdo_leave_one_process_out_k\u001b[0;34m(fit_predict_fun, df, df_dec, process_ids, k, **fit_predict_params)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefine_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_nbrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_predict_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_predict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4da8cfcbf370>\u001b[0m in \u001b[0;36mfit_predict_xgboost_native\u001b[0;34m(train, test, df_dec, **fit_predict_params)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'num_boost_rounds == {num_boost_round}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/toolbox/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/toolbox/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/toolbox/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1497\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# k_values = list(range(10, 202, 10)) + [None]\n",
    "# learning_rate_values = [0.001]\n",
    "# max_depth_values = [3]\n",
    "# num_boost_round_values = [1000]\n",
    "# more_params_values = [{'base_score': 0.0696}]\n",
    "\n",
    "k_values = [40]\n",
    "learning_rate_values = [0.1, 0.01, 0.001]\n",
    "max_depth_values = [2, 3, 4, 5, 10]\n",
    "num_boost_round_values = [1000]\n",
    "more_params_values = [{\"base_score\": 0.0696}]\n",
    "\n",
    "for more_params in more_params_values:\n",
    "    for k in k_values:\n",
    "        for num_boost_round in num_boost_round_values:\n",
    "            for learning_rate in learning_rate_values:\n",
    "                for max_depth in max_depth_values:\n",
    "                    x = do_leave_one_process_out_k(\n",
    "                        fit_predict_xgboost_native,\n",
    "                        df,\n",
    "                        df_dec,\n",
    "                        process_ids,\n",
    "                        k=k,\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        learning_rate=learning_rate,\n",
    "                        max_depth=max_depth,\n",
    "                        **more_params,\n",
    "                    )\n",
    "                    pd.DataFrame(\n",
    "                        {\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}\n",
    "                    ).to_csv(\n",
    "                        TMP_DIR\n",
    "                        / XGBOOST_FILENAME_OUT_TEMPLATE.format(\n",
    "                            dataset=pathlib.Path(data_filepath).stem,\n",
    "                            k=k,\n",
    "                            num_boost_round=num_boost_round,\n",
    "                            learning_rate=learning_rate,\n",
    "                            max_depth=max_depth,\n",
    "                            **more_params,\n",
    "                        ),\n",
    "                        sep=\";\",\n",
    "                        index=False,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "max_depth = 3\n",
    "num_boost_round = 1000\n",
    "more_params = {\"base_score\": 0.0696}\n",
    "\n",
    "x = do_leave_one_process_out_same_category(\n",
    "    fit_predict_xgboost_native,\n",
    "    df,\n",
    "    df_dec,\n",
    "    process_ids,\n",
    "    process_category,\n",
    "    num_boost_round=num_boost_round,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    **more_params,\n",
    ")\n",
    "pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "    TMP_DIR\n",
    "    / XGBOOST_FILENAME_OUT_TEMPLATE_SAME_CATEGORY.format(\n",
    "        dataset=pathlib.Path(data_filepath).stem,\n",
    "        num_boost_round=num_boost_round,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        **more_params,\n",
    "    ),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_filepath\n",
    "del df\n",
    "del df_dec\n",
    "del process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = FILEPATH_IN\n",
    "df = pd.read_csv(data_filepath, sep=SEP)\n",
    "process_ids = df.pop(\"process_ids\")\n",
    "df_dec = df.pop(\"target\").astype(\"category\").cat.codes\n",
    "df_dec = 1 - df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [33:44, 10.02s/it]\n",
      "68it [03:44,  3.75s/it]"
     ]
    }
   ],
   "source": [
    "k = 40\n",
    "learning_rate = 0.001\n",
    "max_depth = 3\n",
    "num_boost_round = 1000\n",
    "more_params = {\"base_score\": 0.0696}\n",
    "\n",
    "for group_name in group_names:\n",
    "    logging.info(f\"feature group {group_name}\")\n",
    "    columns_to_remove = feature_groups[feature_groups[\"group_name\"] == group_name][\n",
    "        \"annonymized_name\"\n",
    "    ].to_list()\n",
    "    df_without_features = df.drop(columns=columns_to_remove)\n",
    "    x = do_leave_one_process_out_k(\n",
    "        fit_predict_xgboost_native,\n",
    "        df_without_features,\n",
    "        df_dec,\n",
    "        process_ids,\n",
    "        k=k,\n",
    "        num_boost_round=num_boost_round,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        **more_params,\n",
    "    )\n",
    "    pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "        TMP_DIR\n",
    "        / XGBOOST_WO_FEATURES_FILENAME_OUT_TEMPLATE.format(\n",
    "            dataset=pathlib.Path(data_filepath).stem,\n",
    "            k=k,\n",
    "            num_boost_round=num_boost_round,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            group_name=group_name.replace(\" \", \"_\"),\n",
    "            **more_params,\n",
    "        ),\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_filepath\n",
    "del df\n",
    "del df_dec\n",
    "del process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment history\n",
      "['number_of_honors_and_awards', 'number_of_honors_and_awards_in_last_but_1_calendar_year', 'person_number_of_honors_and_awards_in_last_but_02_10', 'number_of_honors_and_awards_within_12_recent_months', 'number_of_honors_and_awards_within_24_recent_months', 'number_of_jobs', 'number_of_jobs_in_last_but_1_calendar_year', 'person_number_of_jobs_in_last_but_02_10', 'number_of_jobs_within_6_recent_months', 'number_of_jobs_within_12_recent_months', 'number_of_jobs_within_24_recent_months', 'person_jobs_country_count', 'person_jobs_city_count', 'jobs_start_timestamp', 'jobs_end_timestamp', 'shortest_employment_length_in_months', 'avg_employment_length_in_months', 'number_of_projects', 'number_of_projects_finished_in_last_but_1_calendar_year', 'person_number_of_projects_finished_in_last_but_02_10', 'number_of_projects_finished_within_1_recent_months', 'number_of_projects_finished_within_3_recent_months', 'number_of_projects_finished_within_6_recent_months', 'number_of_projects_finished_within_12_recent_months', 'number_of_projects_finished_within_24_recent_months', 'number_of_volunteer', 'person_industry_group==Internet', 'person_industry_group==Computer Software', 'person_industry_group==Information Technology and Services', 'person_industry_group==Other', 'person_industry_group==Other_IT', 'person_industry_group==NA', 'jobs_start_timestamp==NA', 'jobs_end_timestamp==NA', 'shortest_employment_length_in_months==NA', 'avg_employment_length_in_months==NA']\n",
      "skills\n",
      "['number_of_certifications', 'number_of_certifications_in_last_but_1_calendar_year', 'person_number_of_certifications_in_last_but_02_10', 'number_of_certifications_within_6_recent_months', 'number_of_certifications_within_12_recent_months', 'number_of_certifications_within_24_recent_months', 'number_of_skills', 'frontend_in_any_job_title', 'backend_in_any_job_title', 'fullstack_in_any_job_title', 'developer_in_any_job_title', 'qa_in_any_job_title', 'data_in_any_job_title', 'number_of_languages', 'number_of_courses', 'number_of_publications', 'number_of_publications_in_last_but_1_calendar_year', 'person_number_of_publications_in_last_but_02_10', 'number_of_publications_within_12_recent_months', 'number_of_publications_within_24_recent_months', 'skill_Boo', 'skill_Apple', 'skill_informatyka', 'skill_języki_programowania', 'skill_4D', 'skill_ABAP', 'skill_ActionScript', 'skill_Ada', 'skill_Algol', 'skill_Angelscript', 'skill_Apex', 'skill_APL', 'skill_AppleScript', 'skill_Arc', 'skill_Arduino', 'skill_ASP', 'skill_AspectJ', 'skill_Assembly_language', 'skill_AutoHotkey', 'skill_AutoIt', 'skill_Awk', 'skill_Bash', 'skill_BETA', 'skill_Bourne_shell', 'skill_C', 'skill_C#', 'skill_C++', 'skill_C++/CLI', 'skill_Caml', 'skill_CFML', 'skill_cg', 'skill_CL', 'skill_Clean', 'skill_Clojure', 'skill_COBOL', 'skill_CoffeeScript', 'skill_ColdFusion', 'skill_Common_Lisp', 'skill_Coq', 'skill_Crystal', 'skill_cT', 'skill_Curl', 'skill_D', 'skill_Dart', 'skill_DCL', 'skill_Delphi', 'skill_E', 'skill_ECMAScript', 'skill_EGL', 'skill_Elixir', 'skill_Elm', 'skill_Emacs_Lisp', 'skill_Erlang', 'skill_EXEC', 'skill_F#', 'skill_Factor', 'skill_Falcon', 'skill_Forth', 'skill_Fortran', 'skill_FoxPro', 'skill_GNU_Octave', 'skill_Go', 'skill_Gosu', 'skill_Groovy', 'skill_Haskell', 'skill_haXe', 'skill_Icon', 'skill_IDL', 'skill_INTERCAL', 'skill_Io', 'skill_J', 'skill_JADE', 'skill_Java', 'skill_JavaScript', 'skill_JScript', 'skill_Julia', 'skill_Kotlin', 'skill_LabVIEW', 'skill_Ladder_Logic', 'skill_Limbo', 'skill_Lisp', 'skill_Logo', 'skill_LPC', 'skill_Lua', 'skill_Lustre', 'skill_M4', 'skill_Magic', 'skill_MANTIS', 'skill_Maple', 'skill_Mathematica', 'skill_Matlab', 'skill_Mercury', 'skill_ML', 'skill_Monkey', 'skill_MQL4', 'skill_MS-DOS_Batch', 'skill_NATURAL', 'skill_NSIS', 'skill_Objective-C', 'skill_Objective-J', 'skill_OCaml', 'skill_ooc', 'skill_Opa', 'skill_OpenCL', 'skill_Pascal', 'skill_Perl', 'skill_PHP', 'skill_Pike', 'skill_PILOT', 'skill_PL/SQL', 'skill_PL/pgSQL', 'skill_PostScript', 'skill_PowerShell', 'skill_Processing', 'skill_Prolog', 'skill_Puppet', 'skill_Pure_Data', 'skill_Python', 'skill_Q', 'skill_R', 'skill_Racket', 'skill_REBOL', 'skill_REXX', 'skill_Ring', 'skill_RPG', 'skill_Ruby', 'skill_Rust', 'skill_S', 'skill_SAS', 'skill_Scala', 'skill_Scheme', 'skill_Scilab', 'skill_Scratch', 'skill_sed', 'skill_Self', 'skill_Shell', 'skill_SIGNAL', 'skill_Simulink', 'skill_Smalltalk', 'skill_Smarty', 'skill_SPARK', 'skill_SPSS', 'skill_SQR', 'skill_Squirrel', 'skill_Stata', 'skill_Swift', 'skill_Tcl', 'skill_Tex', 'skill_TOM', 'skill_Transact-SQL', 'skill_Turing', 'skill_TypeScript', 'skill_VBA', 'skill_VBScript', 'skill_Verilog', 'skill_VHDL', 'skill_Visual_Basic', 'skill_Visual_Basic_.NET', 'skill_xBase', 'skill_Xen', 'skill_XQuery', 'skill_XSLT', 'skill_yacc', 'skill_Cairngorm', 'skill_Flex', 'skill_PureMVC', 'skill_Swiz', 'skill_ASP.NET', 'skill_ASP.NET_MVC', 'skill_Compojure', 'skill_Ring_1', 'skill_Phoenix', 'skill_Elm_1', 'skill_Gin', 'skill_Revel', 'skill_beego', 'skill_Grails', 'skill_Grain', 'skill_Snap', 'skill_servant', 'skill_Cocoon', 'skill_Dropwizard', 'skill_Google_Web_Toolkit', 'skill_JSF', 'skill_Ninja', 'skill_Restlet', 'skill_Spring', 'skill_Stripes', 'skill_Struts', 'skill_Tapestry', 'skill_Vaadin', 'skill_Vert.x', 'skill_Wicket', 'skill_ZK', 'skill_echo', 'skill_Angular', 'skill_AngularJS', 'skill_Aurelia', 'skill_Dojo', 'skill_Durandal', 'skill_Ember.js', 'skill_Express', 'skill_Feathers', 'skill_Flight', 'skill_Inferno', 'skill_JavaScriptMVC', 'skill_Koa', 'skill_Meteor', 'skill_Mithril', 'skill_React', 'skill_Riot.js', 'skill_Sails.js', 'skill_Vue.js', 'skill_Orbit', 'skill_Vanilla', 'skill_Agavi', 'skill_Aura', 'skill_CakePHP', 'skill_CodeIgniter', 'skill_FuelPHP', 'skill_Kohana', 'skill_Laravel', 'skill_Lithium', 'skill_Phalcon', 'skill_Prado', 'skill_Solar', 'skill_Symfony', 'skill_Yii', 'skill_Zend', 'skill_Catalyst', 'skill_Mason', 'skill_Mojolicious', 'skill_Bottle', 'skill_CherryPy', 'skill_Django', 'skill_Flask', 'skill_Pyramid', 'skill_Tornado', 'skill_TurboGears', 'skill_Zope', 'skill_web2py', 'skill_Cuba', 'skill_Hanami', 'skill_Merb', 'skill_Ramaze', 'skill_Ruby_on_Rails', 'skill_Sinatra', 'skill_Lift', 'skill_Play', 'skill_Scalatra', 'skill_Perfect', 'skill_Vapor', 'skill_programming_platforms', 'skill_information_systems', 'skill_administracja_sieciowa', 'skill_sztuczna_inteligencja', 'skill_teoria_informacji', 'skill_webmastering', 'skill_architektura_procesorów', 'skill_bezpieczeństwo_komputerowe', 'skill_multimedia', 'skill_grafika_komputerowa', 'skill_cyfrowe_przetwarzanie_dźwięku', 'skill_inżynieria_oprogramowania', 'skill_programowanie', 'skill_sprzęt_komputerowy', 'skill_grafika_2D', 'skill_grafika_3D', 'skill_programy_graficzne', 'skill_3D_Studio_Max', 'skill_Catia', 'skill_Maya', 'skill_Rhino', 'skill_Rhinoceros', 'skill_Softimage', 'skill_Softimage_1', 'skill_SolidWorks', 'skill_Vue', 'skill_3D_Coat', 'skill_Wireframes', 'skill_animacja_2D', 'skill_animacja_3D', 'skill_Adobe_After_Effect', 'skill_Adobe_Photoshop', 'skill_Autodesk_Software', 'skill_Cinema_4D', 'skill_Modo', 'skill_SketchUp', 'skill_ZBrush', 'skill_.NET', 'skill_oprogramowanie_renderujące', 'skill_Kinect', 'skill_3D_Printing', 'skill_3D_rendering', 'skill_Redshift', 'skill_Turtle', 'skill_Vray', 'skill_umiejętności_miękkie', 'skill_oprogramowanie_zabezpieczające', 'skill_Vault', 'skill_kontrola_i_zarządzanie_dostępem', 'skill_interakcja_człowiek-komputer', 'skill_dostępność_WWW', 'skill_technologie_mobilne', 'skill_WCDMA', 'skill_XACML', 'skill_systemy_BI', 'skill_BI', 'skill_zarządzanie', 'skill_finanse_i_rachunkowość', 'skill_zgodność', 'skill_CISCO', 'skill_sprzedaż', 'skill_Android', 'skill_Adobe_Illustrator', 'skill_skład_komputerowy', 'skill_InDesign', 'skill_tworzenie_stron_WWW', 'skill_aplikacje_internetowe', 'skill_Away3D', 'skill_Flash', 'skill_Papervision3D', 'skill_Adobe_Dreamweaver', 'skill_Premiere_Pro', 'skill_marketing', 'skill_reklama', 'skill_systemy_operacyjne', 'skill_usługi_sieciowe', 'skill_serwery_WWW', 'skill_serwery_aplikacji', 'skill_Interfejs_programowania_aplikacji', 'skill_Blackberry_OS', 'skill_Windows_Server', 'skill_Unix', 'skill_Linux', 'skill_Zarządzanie_czasem', 'skill_Zarządzanie_jakością', 'skill_Zarządzanie_projektem', 'skill_zarządzanie_zasobami_ludzkimi', 'skill_Zarządzanie_zespołem', 'skill_Zarządzanie_zmianą', 'skill_Zarządzanie_ryzykiem', 'skill_Systemy_Zarządzania_Bazami_Danych_(relacyjne_lub_obiektowo-relacyjne)', 'skill_Oracle_SZBD', 'skill_Big_Data', 'skill_hurtownie_danych', 'skill_Hadoop', 'skill_bazy_danych_No_SQL', 'skill_Cassandra', 'skill_network_protocols', 'skill_Dagger', 'skill_użytkowanie_oprogramowania', 'skill_Mac_OS', 'skill_SmartWatch', 'skill_architektura_aplikacji', 'skill_FTP', 'skill_IGMP', 'skill_IMAP', 'skill_LDAP', 'skill_POP', 'skill_POP3', 'skill_PPPoE', 'skill_AMQP', 'skill_CAMEL', 'skill_DHCP', 'skill_DNS', 'skill_DHCP_1', 'skill_Jabber', 'skill_RADIUS', 'skill_SIP', 'skill_SMTP', 'skill_SNMP', 'skill_SPICE', 'skill_SSL', 'skill_TCP/IP', 'skill_Telnet', 'skill_UDP', 'skill_WebSockets', 'skill_XMPP', 'skill_HTTP', 'skill_HTTPS', 'skill_IRC', 'skill_SSH', 'skill_bitcoin', 'skill_Tunneling', 'skill_SDP', 'skill_migracja_i_integracja_danych', 'skill_desktopowe_bazy_danych', 'skill_dodatkowe_umiejętności', 'skill_MS_Office', 'skill_MS_Access', 'skill_eksploracja_danych', 'skill_narzędzia_BI', 'skill_Pentaho_BI', 'skill_MS_Visual_Studio', 'skill_zintegrowane_środowiska_programistyczne', 'skill_muzyka', 'skill_nawigacja', 'skill_standardy', 'skill_UML', 'skill_Talend', 'skill_CSS', 'skill_HTML', 'skill_przepływ_pracy', 'skill_metodologie_programowania', 'skill_Eclipse', 'skill_SQL', 'skill_VPN', 'skill_testowanie_oprogramowania', 'skill_Oracle_Data_Integrator', 'skill_AB_Initio', 'skill_Oracle_BI_EE', 'skill_Oracle_Discoverer', 'skill_projektowanie_systemów_informatycznych', 'skill_narzędzia_CASE', 'skill_architektura_komputerów', 'skill_klastry', 'skill_Solaris_Cluster', 'skill_media_społecznościowe', 'skill_Enterprise_Architect', 'skill_Microsoft_Visio', 'skill_OmniGraffle', 'skill_Rational_Rose', 'skill_ArgoUML', 'skill_SAS_Enterprise_Guide', 'skill_ArgoUML_1', 'skill_Teradata', 'skill_Mongo_DB', 'skill_Jasmine', 'skill_testy_jednostkowe', 'skill_bioinformatyka', 'skill_elektronika', 'skill_przeglądarki_internetowe', 'skill_Firefox', 'skill_Chrome', 'skill_Opera', 'skill_Tableau', 'skill_Symbian', 'skill_data_exchange_formats', 'skill_JSON', 'skill_SQL_Azure', 'skill_GNU', 'skill_SAP_HANA', 'skill_ArangoDB', 'skill_EXASOL', 'skill_IBM_Netezza', 'skill_OrientDB', 'skill_Ubuntu', 'skill_Debian', 'skill_Fedora', 'skill_Kubuntu', 'skill_WatchOS', 'skill_Red_Hat_Linux', 'skill_architektura', 'skill_rodzaje_sieci_komuterowych', 'skill_LAN', 'skill_WAN', 'skill_Ethernet', 'skill_techniki_i_standardy', 'skill_kompresja_danych', 'skill_Greenplum', 'skill_Sybase_Power_Designer', 'skill_Firebird', 'skill_powłoki_systemowe', 'skill_WiFi', 'skill_CL_1', 'skill_CCP', 'skill_DCL_1', 'skill_fish', 'skill_JCL', 'skill_ksh', 'skill_sh', 'skill_TSO', 'skill_Windows_PowerShell', 'skill_zsh', 'skill_Desktop', 'skill_Plasma', 'skill_Unity', 'skill_Dash', 'skill_architektura_1', 'skill_języki_znaczników', 'skill_językoznawstwo', 'skill_przetwarzanie_języka_naturalnego', 'skill_TeX', 'skill_GML', 'skill_XML', 'skill_XHTML', 'skill_Web_Socket', 'skill_standardy_kompresji_danych', 'skill_JPEG', 'skill_algorytmy_szyrowania', 'skill_DES', 'skill_RSA', 'skill_DSA', 'skill_bankowość', 'skill_OWL', 'skill_ASN.1', 'skill_RSS', 'skill_Atom', 'skill_RDF', 'skill_automatyka_przemysłowa', 'skill_protokoły_komunikacyjne', 'skill_modbus', 'skill_profibus', 'skill_MPEG', 'skill_Quicktime', 'skill_standardy_przekazywania_informacji_dźwiękowych', 'skill_MIDI', 'skill_szyfrowanie', 'skill_LonWorks', 'skill_magistrala_komunikacyjna', 'skill_CAN_bus', 'skill_DeviceNet', 'skill_MPI', 'skill_OPC', 'skill_protokoły_transmisji_danych', 'skill_ZigBee', 'skill_przemysł_samochodowy', 'skill_ARIA', 'skill_LevelDB', 'skill_MariaDB', 'skill_BigTable', 'skill_Realm', 'skill_Aerospike', 'skill_CORBA', 'skill_XPath', 'skill_HSQLDB', 'skill_XAML', 'skill_XUL', 'skill_Enterprise_JavaBeans_(EJB)', 'skill_Object-relational_mapping_(ORM)', 'skill_interfejs_użytkownika', 'skill_MapReduce', 'skill_doświadczenie_użytkownika', 'skill_IPv4', 'skill_jQuery', 'skill_IPv6', 'skill_RTP', 'skill_MQTT', 'skill_SOAP', 'skill_FreeRTOS', 'skill_planowanie', 'skill_rekrutacja_pracowników', 'skill_mikrokontrolery', 'skill_projektowanie_graficzne', 'skill_Adobe_Acrobat', 'skill_Adobe_Fireworks', 'skill_Adobe_Flash', 'skill_Adobe_InDesign', 'skill_Adobe_Premiere_Pro']\n",
      "education\n",
      "['number_of_schools', 'number_of_schools_finished_in_last_but_0_calendar_year', 'number_of_schools_finished_in_last_but_1_calendar_year', 'person_number_of_schools_finished_in_last_but_02_10', 'number_of_schools_finished_within_1_recent_months', 'number_of_schools_finished_within_3_recent_months', 'number_of_schools_finished_within_6_recent_months', 'number_of_schools_finished_within_12_recent_months', 'number_of_schools_finished_within_24_recent_months', 'education_start_timestamp', 'education_end_timestamp', 'bachelor_in_any_degree_or_field', 'master_in_any_degree_or_field', 'engineer_in_any_degree_or_field', 'doctor_in_any_degree_or_field', 'education_start_timestamp==NA', 'education_end_timestamp==NA']\n",
      "place of residence\n",
      "['country_population', 'person_country_currency_relation_to_PLN', 'en_in_person_country_languages', 'de_in_person_country_languages', 'fr_in_person_country_languages', 'pl_in_person_country_languages', 'ru_in_person_country_languages', 'es_in_person_country_languages', 'country_gdp', 'country_gdp_per_capita', 'country_unemployment_rate', 'country_developers_count', 'city_population', 'city_latitude', 'city_longitude', 'country_population==NA', 'country_continent==EU', 'country_continent==Other', 'country_continent==NA', 'country_currency_code==PLN', 'country_currency_code==Other', 'country_currency_code==EUR', 'country_currency_code==Other_strong', 'country_currency_code==NA', 'en_in_person_country_languages==NA', 'de_in_person_country_languages==NA', 'fr_in_person_country_languages==NA', 'pl_in_person_country_languages==NA', 'ru_in_person_country_languages==NA', 'es_in_person_country_languages==NA', 'country_cluster==Poland', 'country_cluster==Other_ES_EU', 'country_cluster==GF_EU', 'country_cluster==Other', 'country_cluster==SCA', 'country_cluster==UK_Ireland', 'country_cluster==Scandinavian', 'country_cluster==Other_SW_EU', 'country_cluster==CEE', 'country_cluster==Ukraine', 'country_cluster==NA', 'country_gdp==NA', 'country_gdp_per_capita==NA', 'country_unemployment_rate==NA', 'country_developers_count==NA', 'city_population==NA', 'city_latitude==NA', 'city_longitude==NA']\n",
      "current status\n",
      "['candidate_has_github', 'frontend_in_title', 'backend_in_title', 'fullstack_in_title', 'developer_in_title', 'qa_in_title', 'data_in_title', 'person_contact_for_career_opps', 'person_contact_for_consulting', 'person_contact_for_new_ventures', 'person_contact_for_job_inquiries', 'person_contact_for_expertise', 'person_contact_for_business', 'person_contact_for_reference', 'description_no_of_words', 'current_job_employment_length_in_months', 'current_job_recommendations', 'number_of_groups', 'number_of_recommendations', 'number_of_company_following', 'person_contact_for_career_opps==NA', 'person_contact_for_consulting==NA', 'person_contact_for_new_ventures==NA', 'person_contact_for_job_inquiries==NA', 'person_contact_for_expertise==NA', 'person_contact_for_business==NA', 'person_contact_for_reference==NA', 'current_job_employment_length_in_months==NA', 'current_job_recommendations==NA']\n",
      "job offer\n",
      "['recruitment_is_remote', 'recruitment_country_population', 'pl_in_recruitment_country_languages', 'recruitment_country_gdp', 'recruitment_country_gdp_per_capita', 'recruitment_country_unemployment_rate', 'recruitment_country_developers_count', 'recruitment_city_latitude', 'recruitment_city_longitude', 'recruitment_city_population', 'recruitment_frontend_in_role_name', 'recruitment_backend_in_role_name', 'recruitment_fullstack_in_role_name', 'recruitment_developer_in_role_name', 'recruitment_qa_in_role_name', 'recruitment_data_in_role_name', 'recruitment_role_category==BACKEND', 'recruitment_role_category==FRONTEND', 'recruitment_role_category==FULLSTACK', 'recruitment_role_category==UI/UX', 'recruitment_role_category==Other', 'recruitment_role_category==INFRA', 'recruitment_role_category==BIG DATA', 'recruitment_role_category==PRODUCT', 'recruitment_role_category==MOBILE', 'recruitment_role_category==QA', 'role_category_cluster==BACKEND', 'role_category_cluster==FRONTEND', 'role_category_cluster==FULLSTACK', 'role_category_cluster==Other', 'role_category_cluster==INFRA', 'role_category_cluster==BIG DATA', 'recruitment_country_population==NA', 'recruitment_country_currency_code==PLN', 'recruitment_country_currency_code==EUR', 'recruitment_country_currency_code==GBP', 'pl_in_recruitment_country_languages==NA', 'recruitment_country_cluster==Poland', 'recruitment_country_cluster==GF_EU', 'recruitment_country_cluster==Remote', 'recruitment_country_cluster==UK_Ireland', 'recruitment_country_cluster==Other_SW_EU', 'recruitment_country_cluster==NA', 'recruitment_country_gdp==NA', 'recruitment_country_gdp_per_capita==NA', 'recruitment_country_unemployment_rate==NA', 'recruitment_country_developers_count==NA', 'recruitment_city_latitude==NA', 'recruitment_city_longitude==NA', 'recruitment_city_population==NA']\n",
      "person-offer relation\n",
      "['offer_description_similarity', 'offer_title_similarity', 'offer_in_different_country', 'offer_in_different_city', 'offer_common_country_languages', 'offer_in_neighbouring_country', 'offer_in_any_of_school_country', 'offer_in_any_of_school_city', 'offer_in_any_of_jobs_country', 'offer_in_any_of_jobs_city', 'offer_in_any_of_recommendations_country', 'offer_in_any_of_recommendations_city', 'offer_in_different_country==NA', 'offer_in_different_city==NA', 'offer_common_country_languages==NA', 'offer_in_neighbouring_country==NA', 'offer_in_any_of_school_country==NA', 'offer_in_any_of_school_city==NA', 'offer_in_any_of_jobs_country==NA', 'offer_in_any_of_jobs_city==NA', 'offer_in_any_of_recommendations_country==NA', 'offer_in_any_of_recommendations_city==NA']\n"
     ]
    }
   ],
   "source": [
    "for group_name in group_names:\n",
    "    columns_to_remove = feature_groups[feature_groups[\"group_name\"] == group_name][\n",
    "        \"column_name\"\n",
    "    ].to_list()\n",
    "    print(group_name)\n",
    "    print(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = FILEPATH_IN\n",
    "df = pd.read_csv(data_filepath, sep=SEP)\n",
    "process_ids = df.pop(\"process_ids\")\n",
    "df_dec = df.pop(\"target\").astype(\"category\").cat.codes\n",
    "df_dec = 1 - df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:20,  9.72it/s]\n",
      "202it [00:21,  9.43it/s]\n",
      "202it [00:22,  9.11it/s]\n",
      "202it [00:22,  8.82it/s]\n",
      "202it [00:20,  9.76it/s]\n",
      "202it [00:21,  9.39it/s]\n",
      "179it [00:19,  6.90it/s]"
     ]
    }
   ],
   "source": [
    "k_values = list(range(10, 202, 10)) + [None]\n",
    "min_impurity_decrease_values = [0.0, 0.001]\n",
    "max_depth_values = [2, 3, 4, 5]\n",
    "more_params = {}\n",
    "\n",
    "# k_values = [40]\n",
    "# max_depth_values = [2, 3, 4, 5]\n",
    "# min_impurity_decrease_values = [0.0, 0.001, 0.01, 0.1]\n",
    "# more_params = {}\n",
    "\n",
    "for k in k_values:\n",
    "    for min_impurity_decrease in min_impurity_decrease_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            x = do_leave_one_process_out_k(\n",
    "                fit_predict_decision_tree,\n",
    "                df,\n",
    "                df_dec,\n",
    "                process_ids,\n",
    "                k=k,\n",
    "                min_impurity_decrease=min_impurity_decrease,\n",
    "                max_depth=max_depth,\n",
    "                **more_params,\n",
    "            )\n",
    "            pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "                TMP_DIR\n",
    "                / TREE_FILENAME_OUT_TEMPLATE.format(\n",
    "                    dataset=pathlib.Path(data_filepath).stem,\n",
    "                    k=k,\n",
    "                    min_impurity_decrease=min_impurity_decrease,\n",
    "                    max_depth=max_depth,\n",
    "                    **more_params,\n",
    "                ),\n",
    "                sep=\";\",\n",
    "                index=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_impurity_decrease = 0.0\n",
    "max_depth = 5\n",
    "more_params = {}\n",
    "\n",
    "x = do_leave_one_process_out_same_category(\n",
    "    fit_predict_decision_tree,\n",
    "    df,\n",
    "    df_dec,\n",
    "    process_ids,\n",
    "    process_category,\n",
    "    min_impurity_decrease=min_impurity_decrease,\n",
    "    max_depth=max_depth,\n",
    "    **more_params,\n",
    ")\n",
    "pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "    TMP_DIR\n",
    "    / TREE_FILENAME_OUT_TEMPLATE_SAME_CATEGORY.format(\n",
    "        dataset=pathlib.Path(data_filepath).stem,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        max_depth=max_depth,\n",
    "        **more_params,\n",
    "    ),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_filepath\n",
    "del df\n",
    "del df_dec\n",
    "del process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = FILEPATH_IN\n",
    "df = pd.read_csv(data_filepath, sep=SEP)\n",
    "process_ids = df.pop(\"process_ids\")\n",
    "df_dec = df.pop(\"target\").astype(\"category\").cat.codes\n",
    "df_dec = 1 - df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 40\n",
    "min_impurity_decrease = 0.0\n",
    "max_depth = 5\n",
    "more_params = {}\n",
    "\n",
    "for group_name in group_names:\n",
    "    logging.info(f\"feature group {group_name}\")\n",
    "    columns_to_remove = feature_groups[feature_groups[\"group_name\"] == group_name][\n",
    "        \"annonymized_name\"\n",
    "    ].to_list()\n",
    "    df_without_features = df.drop(columns=columns_to_remove)\n",
    "    x = do_leave_one_process_out_k(\n",
    "        fit_predict_decision_tree,\n",
    "        df_without_features,\n",
    "        df_dec,\n",
    "        process_ids,\n",
    "        k=k,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        max_depth=max_depth,\n",
    "        **more_params,\n",
    "    )\n",
    "    pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "        TMP_DIR\n",
    "        / TREE_WO_FEATURES_FILENAME_OUT_TEMPLATE.format(\n",
    "            dataset=pathlib.Path(data_filepath).stem,\n",
    "            k=k,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            max_depth=max_depth,\n",
    "            group_name=group_name.replace(\" \", \"_\"),\n",
    "            **more_params,\n",
    "        ),\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_filepath\n",
    "del df\n",
    "del df_dec\n",
    "del process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bireducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = DISCRETIZED_FILEPATH_IN\n",
    "df = pd.read_csv(data_filepath, sep=DISCRETIZED_SEP)\n",
    "process_ids = df.pop(\"process_ids\")\n",
    "df = df.astype(\"category\")\n",
    "df = df.apply(lambda x: x.cat.codes)\n",
    "df_dec = df.pop(\"target\")\n",
    "df_dec = 1 - df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_values = [20, 50, 80, 110, 140, 170, 200]\n",
    "# k_values = [10, 30, 60, 70, 90, 100, 120, 130, 150, 160, 180, 190, None]\n",
    "k_values = list(range(10, 202, 10)) + [None]\n",
    "n_bireducts_values = [1000]\n",
    "candidate_n_attrs_values = [100]\n",
    "allowed_randomness_values = [0.05]\n",
    "max_n_attrs_values = [None]\n",
    "# max_n_attrs_values = [3]\n",
    "more_params = {}\n",
    "\n",
    "for iteration in range(1):\n",
    "    #     if iteration < 1:\n",
    "    #         continue\n",
    "    for k in k_values:\n",
    "        #         if k < 70:\n",
    "        #             continue\n",
    "        for n_bireducts in n_bireducts_values:\n",
    "            for candidate_n_attrs in candidate_n_attrs_values:\n",
    "                for allowed_randomness in allowed_randomness_values:\n",
    "                    for max_n_attrs in max_n_attrs_values:\n",
    "                        x = do_leave_one_process_out_k(\n",
    "                            fit_predict_bireducts,\n",
    "                            df,\n",
    "                            df_dec,\n",
    "                            process_ids,\n",
    "                            k=k,\n",
    "                            n_bireducts=n_bireducts,\n",
    "                            candidate_n_attrs=candidate_n_attrs,\n",
    "                            allowed_randomness=allowed_randomness,\n",
    "                            max_n_attrs=max_n_attrs,\n",
    "                            **more_params,\n",
    "                        )\n",
    "                        pd.DataFrame(\n",
    "                            {\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}\n",
    "                        ).to_csv(\n",
    "                            TMP_DIR\n",
    "                            / BIREDUCTS_FILENAME_OUT_TEMPLATE.format(\n",
    "                                dataset=pathlib.Path(data_filepath).stem,\n",
    "                                k=k,\n",
    "                                n_bireducts=n_bireducts,\n",
    "                                candidate_n_attrs=candidate_n_attrs,\n",
    "                                allowed_randomness=allowed_randomness,\n",
    "                                max_n_attrs=max_n_attrs,\n",
    "                                iteration=iteration,\n",
    "                                **more_params,\n",
    "                            ),\n",
    "                            sep=\";\",\n",
    "                            index=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bireducts = 1000\n",
    "candidate_n_attrs = 100\n",
    "allowed_randomness = 0.05\n",
    "max_n_attrs = 3\n",
    "iteration = 1\n",
    "x = do_leave_one_process_out_same_category(\n",
    "    fit_predict_bireducts,\n",
    "    df,\n",
    "    df_dec,\n",
    "    process_ids,\n",
    "    process_category,\n",
    "    n_bireducts=n_bireducts,\n",
    "    candidate_n_attrs=candidate_n_attrs,\n",
    "    allowed_randomness=allowed_randomness,\n",
    "    max_n_attrs=max_n_attrs,\n",
    "    **more_params,\n",
    ")\n",
    "pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "    TMP_DIR\n",
    "    / BIREDUCTS_FILENAME_OUT_TEMPLATE_SAME_CATEGORY.format(\n",
    "        dataset=pathlib.Path(data_filepath).stem,\n",
    "        n_bireducts=n_bireducts,\n",
    "        candidate_n_attrs=candidate_n_attrs,\n",
    "        allowed_randomness=allowed_randomness,\n",
    "        max_n_attrs=max_n_attrs,\n",
    "        iteration=iteration,\n",
    "        **more_params,\n",
    "    ),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_filepath\n",
    "del df\n",
    "del df_dec\n",
    "del process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bireducts without features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = DISCRETIZED_FILEPATH_IN\n",
    "df = pd.read_csv(data_filepath, sep=DISCRETIZED_SEP)\n",
    "process_ids = df.pop(\"process_ids\")\n",
    "df = df.astype(\"category\")\n",
    "df = df.apply(lambda x: x.cat.codes)\n",
    "df_dec = df.pop(\"target\")\n",
    "df_dec = 1 - df_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [06:05, 44.05s/it]"
     ]
    }
   ],
   "source": [
    "k = 40\n",
    "n_bireducts = 1000\n",
    "candidate_n_attrs = 100\n",
    "allowed_randomness = 0.05\n",
    "max_n_attrs = None\n",
    "iteration = 1\n",
    "more_params = {}\n",
    "\n",
    "for group_name in group_names:\n",
    "    logging.info(f\"feature group {group_name}\")\n",
    "    columns_to_remove = feature_groups[feature_groups[\"group_name\"] == group_name][\n",
    "        \"annonymized_name\"\n",
    "    ].to_list()\n",
    "    df_without_features = df.drop(columns=columns_to_remove)\n",
    "    x = do_leave_one_process_out_k(\n",
    "        fit_predict_bireducts,\n",
    "        df_without_features,\n",
    "        df_dec,\n",
    "        process_ids,\n",
    "        k=k,\n",
    "        n_bireducts=n_bireducts,\n",
    "        candidate_n_attrs=candidate_n_attrs,\n",
    "        allowed_randomness=allowed_randomness,\n",
    "        max_n_attrs=max_n_attrs,\n",
    "        **more_params,\n",
    "    )\n",
    "    pd.DataFrame({\"scores\": x[0], \"counts\": x[1], \"counts2\": x[2]}).to_csv(\n",
    "        TMP_DIR\n",
    "        / BIREDUCTS_WO_FEATURES_FILENAME_OUT_TEMPLATE.format(\n",
    "            dataset=pathlib.Path(data_filepath).stem,\n",
    "            k=k,\n",
    "            n_bireducts=n_bireducts,\n",
    "            candidate_n_attrs=candidate_n_attrs,\n",
    "            allowed_randomness=allowed_randomness,\n",
    "            max_n_attrs=max_n_attrs,\n",
    "            iteration=iteration,\n",
    "            group_name=group_name.replace(\" \", \"_\"),\n",
    "            **more_params,\n",
    "        ),\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cf615238d2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdata_filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf_dec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mprocess_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_filepath' is not defined"
     ]
    }
   ],
   "source": [
    "del data_filepath\n",
    "del df\n",
    "del df_dec\n",
    "del process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb353cb8b9a4ebafc945efb5c6e15e592d37ff0fcf51b748ec6c5769c1eaa51b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
